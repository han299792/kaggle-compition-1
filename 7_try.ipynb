{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboosting + hyper parameter tunung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_pred.csv 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def convert_time_to_minutes(time_str): \n",
    "    hours, minutes = time_str.split('h')\n",
    "    hours = float(hours.strip()) \n",
    "    minutes = minutes.replace('m', '').strip()\n",
    "    minutes = int(minutes) if minutes else 0\n",
    "    total_minutes = int(round(hours * 60)) + minutes\n",
    "    return total_minutes\n",
    "\n",
    "def time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "    \n",
    "reference_date = pd.to_datetime('2022-02-11')\n",
    "train_data = pd.read_csv('./gist-mldl24f-hw3/train.csv')\n",
    "\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "train_data['num_code'] = train_data['num_code'].astype(str)\n",
    "train_data['time_taken'] = train_data['time_taken'].apply(convert_time_to_minutes)\n",
    "train_data['dep_time'] = pd.to_datetime(train_data['dep_time'], format='%H:%M')\n",
    "train_data['arr_time'] = pd.to_datetime(train_data['arr_time'], format='%H:%M')\n",
    "train_data['dep_time_period'] = train_data['dep_time'].dt.hour.apply(time_of_day)\n",
    "train_data['arr_time_period'] = train_data['arr_time'].dt.hour.apply(time_of_day)\n",
    "train_data['stop_num'] = train_data['stop'].str.split('-').str[0].map({\n",
    "    'non': 0,\n",
    "    '1': 1,\n",
    "    '2+': 2\n",
    "})\n",
    "train_data['days_since'] = (pd.to_datetime(train_data['date']) - reference_date).dt.days\n",
    "train_data['day_of_week'] = train_data['date'].dt.day_name()\n",
    "train_data['hour_dep'] = train_data['dep_time'].dt.hour\n",
    "train_data['hour_arr'] = train_data['arr_time'].dt.hour\n",
    "test_data = pd.read_csv('./gist-mldl24f-hw3/test.csv')\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "test_data['num_code'] = test_data['num_code'].astype(str)\n",
    "test_data['time_taken'] = test_data['time_taken'].apply(convert_time_to_minutes)\n",
    "test_data['dep_time'] = pd.to_datetime(test_data['dep_time'], format='%H:%M')\n",
    "test_data['arr_time'] = pd.to_datetime(test_data['arr_time'], format='%H:%M')\n",
    "test_data['dep_time_period'] = test_data['dep_time'].dt.hour.apply(time_of_day)\n",
    "test_data['arr_time_period'] = test_data['arr_time'].dt.hour.apply(time_of_day)\n",
    "test_data['stop_num'] = test_data['stop'].str.split('-').str[0].map({\n",
    "    'non': 0,\n",
    "    '1': 1,\n",
    "    '2+': 2\n",
    "})\n",
    "test_data['days_since'] = (pd.to_datetime(test_data['date']) - reference_date).dt.days\n",
    "test_data['day_of_week'] = test_data['date'].dt.day_name()\n",
    "test_data['hour_dep'] = test_data['dep_time'].dt.hour\n",
    "test_data['hour_arr'] = test_data['arr_time'].dt.hour\n",
    "cat_predictors = ['airline', 'from', 'to', 'class', 'dep_time_period', 'arr_time_period', 'day_of_week']\n",
    "num_predictors = ['time_taken', 'days_since','stop_num', 'hour_dep', 'hour_arr']\n",
    "\n",
    "X_cat_train = pd.get_dummies(train_data[cat_predictors], drop_first=True)\n",
    "X_num_train = train_data[num_predictors]\n",
    "X_train = pd.concat([X_num_train, X_cat_train], axis=1)\n",
    "y_train = train_data['price']\n",
    "\n",
    "X_cat_test = pd.get_dummies(test_data[cat_predictors], drop_first=True)\n",
    "X_num_test = test_data[num_predictors]\n",
    "X_test = pd.concat([X_num_test, X_cat_test], axis=1)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(XGBRegressor(random_state=0), param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({'id': test_data['id'], 'price': y_pred_best})\n",
    "result.to_csv('7_pred.csv', index=False)\n",
    "print(\"7_pred.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
